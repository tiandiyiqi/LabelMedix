# 部署与监控方案

**负责人**: Alex  
**协作者**: Bob, David  
**创建时间**: 2025-01-13  
**状态**: 进行中

## 1. 部署环境

### 1.1 环境划分

#### 1.1.1 开发环境 (Development)

- **用途**: 日常开发调试
- **服务器**: 本地开发服务器
- **数据库**: 本地 MySQL 实例
- **缓存**: 本地 Redis 实例
- **域名**: localhost:3000 (前端), localhost:3001 (后端)

#### 1.1.2 测试环境 (Testing)

- **用途**: 功能测试和集成测试
- **服务器**: 测试服务器
- **数据库**: 测试数据库
- **缓存**: 测试 Redis 实例
- **域名**: test.labelmedix.com

#### 1.1.3 预生产环境 (Staging)

- **用途**: 生产环境预演
- **服务器**: 预生产服务器
- **数据库**: 预生产数据库
- **缓存**: 预生产 Redis 实例
- **域名**: staging.labelmedix.com

#### 1.1.4 生产环境 (Production)

- **用途**: 正式用户服务
- **服务器**: 生产服务器集群
- **数据库**: 生产数据库集群
- **缓存**: 生产 Redis 集群
- **域名**: labelmedix.com

### 1.2 服务器配置

#### 1.2.1 开发环境配置

```yaml
# 开发环境配置
development:
  server:
    cpu: 2 cores
    memory: 4GB
    storage: 50GB SSD
    os: Ubuntu 20.04 LTS

  database:
    type: MySQL 8.0
    cpu: 1 core
    memory: 2GB
    storage: 20GB SSD

  cache:
    type: Redis 6.0
    memory: 1GB
```

#### 1.2.2 生产环境配置

```yaml
# 生产环境配置
production:
  server:
    cpu: 8 cores
    memory: 16GB
    storage: 200GB SSD
    os: Ubuntu 22.04 LTS
    instances: 3

  database:
    type: MySQL 8.0 Cluster
    cpu: 4 cores
    memory: 8GB
    storage: 500GB SSD
    instances: 2 (主从)

  cache:
    type: Redis 6.0 Cluster
    memory: 4GB
    instances: 3
```

## 2. 配置说明

### 2.1 环境变量配置

#### 2.1.1 前端环境变量

```bash
# .env.local (开发环境)
NEXT_PUBLIC_API_URL=http://localhost:3001
NEXT_PUBLIC_APP_NAME=LabelMedix
NEXT_PUBLIC_VERSION=1.0.0
NEXT_PUBLIC_ENVIRONMENT=development

# .env.production (生产环境)
NEXT_PUBLIC_API_URL=https://api.labelmedix.com
NEXT_PUBLIC_APP_NAME=LabelMedix
NEXT_PUBLIC_VERSION=1.0.0
NEXT_PUBLIC_ENVIRONMENT=production
```

#### 2.1.2 后端环境变量

```bash
# .env (开发环境)
NODE_ENV=development
PORT=3001
DB_HOST=localhost
DB_PORT=3306
DB_NAME=labelmedix_dev
DB_USERNAME=root
DB_PASSWORD=password
REDIS_HOST=localhost
REDIS_PORT=6379
JWT_SECRET=dev-secret-key
JWT_EXPIRES_IN=7d

# .env.production (生产环境)
NODE_ENV=production
PORT=3001
DB_HOST=mysql-cluster.labelmedix.com
DB_PORT=3306
DB_NAME=labelmedix_prod
DB_USERNAME=labelmedix_user
DB_PASSWORD=secure-password
REDIS_HOST=redis-cluster.labelmedix.com
REDIS_PORT=6379
JWT_SECRET=production-secret-key
JWT_EXPIRES_IN=1d
```

### 2.2 数据库连接配置

#### 2.2.1 Sequelize 配置

```javascript
// config/database.js
module.exports = {
  development: {
    username: process.env.DB_USERNAME || "root",
    password: process.env.DB_PASSWORD || "",
    database: process.env.DB_NAME || "labelmedix_dev",
    host: process.env.DB_HOST || "localhost",
    port: process.env.DB_PORT || 3306,
    dialect: "mysql",
    logging: console.log,
    pool: {
      max: 5,
      min: 0,
      acquire: 30000,
      idle: 10000,
    },
  },
  production: {
    username: process.env.DB_USERNAME,
    password: process.env.DB_PASSWORD,
    database: process.env.DB_NAME,
    host: process.env.DB_HOST,
    port: process.env.DB_PORT || 3306,
    dialect: "mysql",
    logging: false,
    pool: {
      max: 20,
      min: 5,
      acquire: 60000,
      idle: 10000,
    },
    replication: {
      read: [{ host: "mysql-read.labelmedix.com" }],
      write: { host: "mysql-write.labelmedix.com" },
    },
  },
};
```

### 2.3 Redis 配置

#### 2.3.1 Redis 连接配置

```javascript
// config/redis.js
const redis = require("redis");

const createRedisClient = () => {
  const client = redis.createClient({
    host: process.env.REDIS_HOST || "localhost",
    port: process.env.REDIS_PORT || 6379,
    password: process.env.REDIS_PASSWORD,
    db: process.env.REDIS_DB || 0,
    retry_strategy: (options) => {
      if (options.error && options.error.code === "ECONNREFUSED") {
        return new Error("The server refused the connection");
      }
      if (options.total_retry_time > 1000 * 60 * 60) {
        return new Error("Retry time exhausted");
      }
      if (options.attempt > 10) {
        return undefined;
      }
      return Math.min(options.attempt * 100, 3000);
    },
  });

  client.on("error", (err) => {
    console.error("Redis Client Error:", err);
  });

  return client;
};

module.exports = { createRedisClient };
```

## 3. 部署步骤

### 3.1 容器化部署

#### 3.1.1 Docker 配置

##### 前端 Dockerfile

```dockerfile
# FrontEnd/Dockerfile
FROM node:18-alpine AS base

# Install dependencies only when needed
FROM base AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app

# Install dependencies based on the preferred package manager
COPY package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./
RUN \
  if [ -f yarn.lock ]; then yarn --frozen-lockfile; \
  elif [ -f package-lock.json ]; then npm ci; \
  elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm && pnpm i --frozen-lockfile; \
  else echo "Lockfile not found." && exit 1; \
  fi

# Rebuild the source code only when needed
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Next.js collects completely anonymous telemetry data about general usage.
# Learn more here: https://nextjs.org/telemetry
# Uncomment the following line in case you want to disable telemetry during the build.
# ENV NEXT_TELEMETRY_DISABLED 1

RUN yarn build

# Production image, copy all the files and run next
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production
# Uncomment the following line in case you want to disable telemetry during runtime.
# ENV NEXT_TELEMETRY_DISABLED 1

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public

# Set the correct permission for prerender cache
RUN mkdir .next
RUN chown nextjs:nodejs .next

# Automatically leverage output traces to reduce image size
# https://nextjs.org/docs/advanced-features/output-file-tracing
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000

ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "server.js"]
```

##### 后端 Dockerfile

```dockerfile
# BackEnd/Dockerfile
FROM node:18-alpine

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci --only=production

# Copy source code
COPY . .

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# Change ownership
RUN chown -R nodejs:nodejs /app
USER nodejs

EXPOSE 3001

CMD ["npm", "start"]
```

#### 3.1.2 Docker Compose 配置

```yaml
# docker-compose.yml
version: "3.8"

services:
  frontend:
    build: ./FrontEnd
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:3001
    depends_on:
      - backend
    networks:
      - labelmedix-network

  backend:
    build: ./BackEnd
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - DB_HOST=mysql
      - REDIS_HOST=redis
    depends_on:
      - mysql
      - redis
    networks:
      - labelmedix-network

  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=labelmedix
      - MYSQL_USER=labelmedix
      - MYSQL_PASSWORD=password
    volumes:
      - mysql_data:/var/lib/mysql
    ports:
      - "3306:3306"
    networks:
      - labelmedix-network

  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - labelmedix-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - labelmedix-network

volumes:
  mysql_data:
  redis_data:

networks:
  labelmedix-network:
    driver: bridge
```

### 3.2 Nginx 配置

#### 3.2.1 Nginx 主配置

```nginx
# nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;

    # Upstream servers
    upstream frontend {
        server frontend:3000;
    }

    upstream backend {
        server backend:3001;
    }

    # HTTP server (redirect to HTTPS)
    server {
        listen 80;
        server_name labelmedix.com www.labelmedix.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS server
    server {
        listen 443 ssl http2;
        server_name labelmedix.com www.labelmedix.com;

        # SSL configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # Frontend
        location / {
            proxy_pass http://frontend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # API
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # Login endpoint (stricter rate limiting)
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Static files
        location /static/ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            proxy_pass http://frontend;
        }
    }
}
```

### 3.3 部署脚本

#### 3.3.1 自动化部署脚本

```bash
#!/bin/bash
# deploy.sh

set -e

echo "Starting deployment..."

# 1. 拉取最新代码
echo "Pulling latest code..."
git pull origin main

# 2. 构建前端
echo "Building frontend..."
cd FrontEnd
npm ci
npm run build
cd ..

# 3. 构建后端
echo "Building backend..."
cd BackEnd
npm ci
npm run build
cd ..

# 4. 运行数据库迁移
echo "Running database migrations..."
cd BackEnd
npm run db:migrate
cd ..

# 5. 构建 Docker 镜像
echo "Building Docker images..."
docker-compose build

# 6. 停止旧服务
echo "Stopping old services..."
docker-compose down

# 7. 启动新服务
echo "Starting new services..."
docker-compose up -d

# 8. 健康检查
echo "Performing health check..."
sleep 30
curl -f http://localhost/health || exit 1

echo "Deployment completed successfully!"
```

#### 3.3.2 回滚脚本

```bash
#!/bin/bash
# rollback.sh

set -e

echo "Starting rollback..."

# 1. 停止当前服务
echo "Stopping current services..."
docker-compose down

# 2. 回滚到上一个版本
echo "Rolling back to previous version..."
git checkout HEAD~1

# 3. 重新构建和启动
echo "Rebuilding and starting services..."
docker-compose build
docker-compose up -d

# 4. 健康检查
echo "Performing health check..."
sleep 30
curl -f http://localhost/health || exit 1

echo "Rollback completed successfully!"
```

## 4. 监控指标

### 4.1 系统监控指标

#### 4.1.1 服务器监控

```yaml
# 服务器监控指标
server_metrics:
  cpu:
    usage_percent: < 80%
    load_average: < 2.0
    temperature: < 70°C

  memory:
    usage_percent: < 85%
    available_gb: > 2GB
    swap_usage: < 10%

  disk:
    usage_percent: < 90%
    io_wait: < 10ms
    read_write_iops: < 1000

  network:
    bandwidth_usage: < 80%
    packet_loss: < 0.1%
    latency: < 100ms
```

#### 4.1.2 应用监控

```yaml
# 应用监控指标
application_metrics:
  response_time:
    p50: < 200ms
    p95: < 500ms
    p99: < 1000ms

  throughput:
    requests_per_second: > 100
    concurrent_users: > 50

  error_rate:
    http_4xx: < 5%
    http_5xx: < 1%
    application_errors: < 0.1%

  availability:
    uptime: > 99.9%
    downtime: < 8.76 hours/year
```

### 4.2 业务监控指标

#### 4.2.1 用户行为监控

```yaml
# 用户行为监控
user_metrics:
  active_users:
    daily_active_users: > 100
    weekly_active_users: > 500
    monthly_active_users: > 2000

  user_engagement:
    session_duration: > 5 minutes
    pages_per_session: > 3
    bounce_rate: < 30%

  feature_usage:
    label_creation: > 50/day
    pdf_generation: > 100/day
    language_switching: > 200/day
```

#### 4.2.2 业务指标监控

```yaml
# 业务指标监控
business_metrics:
  pdf_generation:
    success_rate: > 99%
    average_generation_time: < 60s
    daily_generations: > 100

  system_performance:
    database_query_time: < 100ms
    cache_hit_rate: > 90%
    api_response_time: < 500ms

  data_quality:
    data_accuracy: > 99%
    data_completeness: > 95%
    data_consistency: > 99%
```

## 5. 告警规则

### 5.1 系统告警规则

#### 5.1.1 服务器告警

```yaml
# 服务器告警规则
server_alerts:
  cpu_usage:
    condition: cpu_usage > 80%
    duration: 5 minutes
    severity: warning
    notification: email, slack

  memory_usage:
    condition: memory_usage > 85%
    duration: 5 minutes
    severity: warning
    notification: email, slack

  disk_usage:
    condition: disk_usage > 90%
    duration: 1 minute
    severity: critical
    notification: email, slack, sms

  service_down:
    condition: service_status != "up"
    duration: 1 minute
    severity: critical
    notification: email, slack, sms
```

#### 5.1.2 应用告警

```yaml
# 应用告警规则
application_alerts:
  response_time:
    condition: p95_response_time > 1000ms
    duration: 5 minutes
    severity: warning
    notification: email, slack

  error_rate:
    condition: error_rate > 5%
    duration: 2 minutes
    severity: critical
    notification: email, slack, sms

  availability:
    condition: availability < 99%
    duration: 1 minute
    severity: critical
    notification: email, slack, sms
```

### 5.2 业务告警规则

#### 5.2.1 PDF 生成告警

```yaml
# PDF 生成告警
pdf_alerts:
  generation_failure:
    condition: pdf_generation_success_rate < 95%
    duration: 5 minutes
    severity: critical
    notification: email, slack, sms

  generation_time:
    condition: avg_generation_time > 120s
    duration: 10 minutes
    severity: warning
    notification: email, slack

  queue_backlog:
    condition: pdf_queue_size > 50
    duration: 5 minutes
    severity: warning
    notification: email, slack
```

## 6. 日志管理

### 6.1 日志配置

#### 6.1.1 应用日志配置

```javascript
// BackEnd/src/utils/logger.js
const winston = require("winston");

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || "info",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: "labelmedix-backend" },
  transports: [
    // 错误日志
    new winston.transports.File({
      filename: "logs/error.log",
      level: "error",
      maxsize: 5242880, // 5MB
      maxFiles: 5,
    }),
    // 组合日志
    new winston.transports.File({
      filename: "logs/combined.log",
      maxsize: 5242880, // 5MB
      maxFiles: 5,
    }),
    // 控制台输出
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
  ],
});

// 生产环境不输出到控制台
if (process.env.NODE_ENV === "production") {
  logger.remove(logger.transports[2]);
}

module.exports = logger;
```

#### 6.1.2 日志格式规范

```javascript
// 日志格式示例
{
  "timestamp": "2025-01-13T10:30:00.000Z",
  "level": "info",
  "message": "PDF generation completed",
  "service": "labelmedix-backend",
  "requestId": "req-123456",
  "userId": "user-789",
  "metadata": {
    "pdfId": "pdf-abc123",
    "language": "CN",
    "pageCount": 1,
    "generationTime": 45000
  }
}
```

### 6.2 日志收集和分析

#### 6.2.1 ELK Stack 配置

```yaml
# docker-compose.logging.yml
version: "3.8"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:
```

#### 6.2.2 Logstash 配置

```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "labelmedix-backend" {
    json {
      source => "message"
    }

    date {
      match => [ "timestamp", "ISO8601" ]
    }

    mutate {
      add_field => { "service" => "labelmedix-backend" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "labelmedix-logs-%{+YYYY.MM.dd}"
  }
}
```

## 7. 问题排查流程

### 7.1 问题分类

#### 7.1.1 严重问题 (P0)

- **定义**: 系统完全不可用，影响所有用户
- **响应时间**: 15 分钟内
- **解决时间**: 1 小时内
- **通知方式**: 电话 + 短信 + 邮件

#### 7.1.2 重要问题 (P1)

- **定义**: 核心功能不可用，影响大部分用户
- **响应时间**: 1 小时内
- **解决时间**: 4 小时内
- **通知方式**: 短信 + 邮件

#### 7.1.3 一般问题 (P2)

- **定义**: 部分功能异常，影响部分用户
- **响应时间**: 4 小时内
- **解决时间**: 24 小时内
- **通知方式**: 邮件

#### 7.1.4 轻微问题 (P3)

- **定义**: 功能正常，但有优化空间
- **响应时间**: 24 小时内
- **解决时间**: 1 周内
- **通知方式**: 邮件

### 7.2 排查步骤

#### 7.2.1 问题发现

1. **监控告警**: 系统自动告警
2. **用户反馈**: 用户主动反馈
3. **主动巡检**: 定期系统检查
4. **日志分析**: 日志异常发现

#### 7.2.2 问题定位

1. **查看监控指标**: 检查系统资源使用情况
2. **分析日志**: 查看错误日志和异常信息
3. **检查服务状态**: 确认各服务运行状态
4. **数据库检查**: 检查数据库连接和性能

#### 7.2.3 问题解决

1. **紧急处理**: 立即恢复服务可用性
2. **根本解决**: 修复根本原因
3. **验证测试**: 确认问题已解决
4. **监控观察**: 持续观察系统状态

#### 7.2.4 问题总结

1. **问题复盘**: 分析问题原因和影响
2. **改进措施**: 制定预防措施
3. **文档更新**: 更新操作手册
4. **团队分享**: 分享经验和教训

### 7.3 常见问题处理

#### 7.3.1 服务不可用

```bash
# 检查服务状态
docker-compose ps

# 查看服务日志
docker-compose logs [service_name]

# 重启服务
docker-compose restart [service_name]

# 检查端口占用
netstat -tlnp | grep :3000
```

#### 7.3.2 数据库连接问题

```bash
# 检查数据库状态
docker-compose exec mysql mysql -u root -p -e "SHOW PROCESSLIST;"

# 检查数据库连接数
docker-compose exec mysql mysql -u root -p -e "SHOW STATUS LIKE 'Threads_connected';"

# 重启数据库
docker-compose restart mysql
```

#### 7.3.3 内存不足问题

```bash
# 检查内存使用
free -h

# 检查进程内存使用
ps aux --sort=-%mem | head -10

# 清理 Docker 资源
docker system prune -a
```

## 8. 备份和恢复策略

### 8.1 数据备份

#### 8.1.1 数据库备份

```bash
#!/bin/bash
# backup-database.sh

# 配置
DB_HOST="mysql"
DB_NAME="labelmedix"
DB_USER="root"
DB_PASS="password"
BACKUP_DIR="/backups/mysql"
DATE=$(date +%Y%m%d_%H%M%S)

# 创建备份目录
mkdir -p $BACKUP_DIR

# 全量备份
docker-compose exec mysql mysqldump \
  -h $DB_HOST \
  -u $DB_USER \
  -p$DB_PASS \
  --single-transaction \
  --routines \
  --triggers \
  $DB_NAME > $BACKUP_DIR/full_backup_$DATE.sql

# 压缩备份文件
gzip $BACKUP_DIR/full_backup_$DATE.sql

# 删除 7 天前的备份
find $BACKUP_DIR -name "*.sql.gz" -mtime +7 -delete

echo "Database backup completed: full_backup_$DATE.sql.gz"
```

#### 8.1.2 文件备份

```bash
#!/bin/bash
# backup-files.sh

# 配置
SOURCE_DIR="/app/uploads"
BACKUP_DIR="/backups/files"
DATE=$(date +%Y%m%d_%H%M%S)

# 创建备份目录
mkdir -p $BACKUP_DIR

# 备份文件
tar -czf $BACKUP_DIR/files_backup_$DATE.tar.gz -C $SOURCE_DIR .

# 删除 30 天前的备份
find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete

echo "Files backup completed: files_backup_$DATE.tar.gz"
```

### 8.2 数据恢复

#### 8.2.1 数据库恢复

```bash
#!/bin/bash
# restore-database.sh

# 配置
DB_HOST="mysql"
DB_NAME="labelmedix"
DB_USER="root"
DB_PASS="password"
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# 解压备份文件
gunzip -c $BACKUP_FILE > /tmp/restore.sql

# 恢复数据库
docker-compose exec mysql mysql \
  -h $DB_HOST \
  -u $DB_USER \
  -p$DB_PASS \
  $DB_NAME < /tmp/restore.sql

# 清理临时文件
rm /tmp/restore.sql

echo "Database restore completed"
```

#### 8.2.2 文件恢复

```bash
#!/bin/bash
# restore-files.sh

# 配置
TARGET_DIR="/app/uploads"
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# 创建目标目录
mkdir -p $TARGET_DIR

# 恢复文件
tar -xzf $BACKUP_FILE -C $TARGET_DIR

echo "Files restore completed"
```

### 8.3 备份策略

#### 8.3.1 备份频率

- **数据库全量备份**: 每日 2:00 AM
- **数据库增量备份**: 每小时
- **文件备份**: 每日 3:00 AM
- **配置文件备份**: 每周日

#### 8.3.2 备份保留

- **全量备份**: 保留 30 天
- **增量备份**: 保留 7 天
- **文件备份**: 保留 90 天
- **配置文件**: 保留 1 年

#### 8.3.3 备份验证

- **每日验证**: 检查备份文件完整性
- **每周恢复测试**: 随机选择备份进行恢复测试
- **每月完整测试**: 完整恢复流程测试

## 9. 系统性能思维链分析

### 9.1 性能优化决策

**问题**: 如何确保系统在高负载下的稳定性能？
**分析过程**:

1. 识别性能瓶颈：数据库查询、PDF 生成、文件 I/O
2. 优化策略：缓存、连接池、异步处理、负载均衡
3. 监控指标：响应时间、吞吐量、资源使用率
4. 扩展方案：水平扩展、垂直扩展、微服务架构
   **解决方案**: 实现多层缓存、数据库连接池、异步 PDF 生成、负载均衡

### 9.2 监控体系设计

**问题**: 如何建立全面的监控体系？
**分析过程**:

1. 监控层次：基础设施、应用、业务、用户体验
2. 监控工具：Prometheus、Grafana、ELK Stack
3. 告警机制：分级告警、多渠道通知
4. 数据分析：趋势分析、异常检测、容量规划
   **解决方案**: 建立四层监控体系，实现自动化告警和智能分析

### 9.3 容灾备份策略

**问题**: 如何确保数据安全和业务连续性？
**分析过程**:

1. 风险评估：硬件故障、软件故障、人为错误、自然灾害
2. 备份策略：全量备份、增量备份、异地备份
3. 恢复方案：RTO（恢复时间目标）、RPO（恢复点目标）
4. 测试验证：定期恢复测试、灾难演练
   **解决方案**: 实现自动化备份、异地容灾、快速恢复机制

---

**文档版本**: v1.0  
**最后更新**: 2025-01-13  
**下次评审**: 2025-01-20
